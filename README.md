# J2D_Hackathon

## 1. Introducción
En primer lugar, describamos los datasets a unificar escogidos y razonamos el por qué de dicha decisión: Como dataset base hemos escogido el dataset "2019_censcomercialbcn_detall.csv" el cual hemos denominado como locals_dt. En él encontraremos la información más relevante sobre los comercios locales disponibles y ocupados en los diferentes distritos y barrios Barcelona en 2019. Por otra parte, nuestro dataset complementario se basa en una combinación de dos datasets los cuales almacenan el precio de alquiler mensual y venta de los distintos locales por barrios en Barcelona. Éstos son los siguientes: "loclloevolucio.csv" y "locveevolucio.csv" los cuales en conjunto serán nombrados como prices_dt.

## 2. Prepocesamiento y depuración de datos
La fase de depuración y preprocesamiento de datos juega un papel crucial para garantizar la calidad y relevancia de la información que utilizaremos en nuestros análisis y clasificaciones. El conjunto de datos proporciona información valiosa sobre los locales, incluyendo detalles como la ubicación geográfica, el tipo de actividad y el distrito al que pertenecen. Nuestro objetivo principal es preparar estos datos de manera que podamos identificar patrones significativos y tomar decisiones informadas para futuras expansiones de negocios. Todo ésto recogido en una aplicación que permita el influjo de comercios y consecuentemente, de clientes con el fin de potenciar el comercio local.

En nuestro caso hemos dividido la depuración de datos en dos procesos diferenciados: (2.1) Depuración previa a la unificación, en el cual hemos tratado los datasets por separado y hemos reducido las variables necesarias y (2.2) Depuración posterior a la unificación, donde hemos seleccionado las variables relevantes del dataset unificado para un fiable tratamiento de datos.

### 2.1. Depuración previa a la unificación


### 2.2. Depuración posterior a la unificación
